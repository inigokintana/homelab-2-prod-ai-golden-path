Steps:

1) Prompt -> embbed all-minilm
2) RAG database SAME encoding all-minilm in vectorizer 
3) SQL comparison with semantic search
UNION with several tables
dapr_web + dapr_docs+ github MCR + 6) steps saved
4) pass search results to Ollama or OpenAI LLM
5) Get LLM answer
6) Save: prompts, embedded, answers, timestamps and user